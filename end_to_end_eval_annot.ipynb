{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f2fe41",
   "metadata": {},
   "source": [
    "# SP+ End-to-end Evaluation: Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f7d6e",
   "metadata": {},
   "source": [
    "## 0. Setting up your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6ab2b",
   "metadata": {},
   "source": [
    "### 0a. git clone the mmda repo to your local device: https://github.com/allenai/mmda\n",
    "Follow the instructions for setting up a virtual environment/requirements for working with this repo. You may need to install various libraries/packages. \n",
    "**Make sure you activate the env using:** _conda activate mmda_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a76a78f",
   "metadata": {},
   "source": [
    "### 0b. git clone extract-stuff-from-pdfs repo to your local device: https://github.com/allenai/extract-stuff-from-pdfs\n",
    "Follow the instructions for setting up your environment for this repo. __Note: This repo is only needed for visualizing the annotations, it is not needed to retrieve them from the annotation store.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa8ab5",
   "metadata": {},
   "source": [
    "## 1. Get data from annotation store\n",
    "Load data from schema into notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b52e509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'docId': '17ada3c96ef888fc89f6b995d2edd19a45383423', 'attributesFromSource': {'spp-test-1': {'plain-text-doc-id': '740c1d64752b4679a742544046cf5de3452cfef4', 'mentions': {'annotation-type': ['PlainText', 'PDF'], 'mention-detection-source': 'mentions-test-3', 'bib-mention-linker-source': 'citation-links-test-1'}, 'bib-entries': {'annotation-type': 'PDF', 'bib-detection-source': 'bib_detector_test_3'}, 'bib-entry-parses': {'annotation-type': 'PDF', 'bib-parsing-source': 'bib-struct-test-1'}, 'pdf-plumber': 'pdfplumber-0.0.4'}}, 'annotationsFromSource': {}}\n"
     ]
    }
   ],
   "source": [
    "# NOTE - if schema changes, need to update \"annotation-type\", \"bib-mention-linker-source\", etc... (one time only)\n",
    "import urllib.request, json \n",
    "\n",
    "# !!!! ANNOTATOR TODO: We will need to change SHA and annotation/attribute source for each paper evaluated\n",
    "sha = '17ada3c96ef888fc89f6b995d2edd19a45383423'\n",
    "\n",
    "\n",
    "attributeSource = \"spp-test-1\"\n",
    "annotationSource = \"spp-test-1\"\n",
    "\n",
    "# get data from json file\n",
    "with urllib.request.urlopen(f\"http://annotations-api.dev.s2.allenai.org/pdf/{sha}/annotations?\"\n",
    "                            f\"annotationSources={annotationSource}&attributeSources={attributeSource}\") as url:\n",
    "    data = json.load(url)\n",
    "    \n",
    "#sanity check, remove later\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9d55b",
   "metadata": {},
   "source": [
    "### 1a. Get source names and endpoint types\n",
    "This part of the notebook will retreive information about where to find the annotation sources for each part - mentions, bib-entries, bib-entry-parses, and pdf plumber. It will also retreive whether the annotations for each source are in the annotation store as a PDF or plain text. These sources will be the inputs for retreiving each type of annotation from the annotation store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7028e3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bfcfb591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['PlainText', 'PDF'], 'citation-links-test-1', 'mentions-test-3'],\n",
       " ['PDF', 'bib_detector_test_3'],\n",
       " ['PDF', 'bib-struct-test-1'],\n",
       " [['PlainText', 'PDF'], 'pdfplumber-0.0.4']]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store sources as variables in case they change later; may need to change strings if schema changes (one time only)\n",
    "mention = \"mentions\"\n",
    "bib_entries = \"bib-entries\"\n",
    "bib_entry_parses = \"bib-entry-parses\"\n",
    "plumber = \"pdf-plumber\"\n",
    "\n",
    "# get source/stored formats in annotation store, store as variables\n",
    "for source_type in data['attributesFromSource'][attributeSource]:  \n",
    "    \n",
    "    # mentions\n",
    "    if source_type == mention:\n",
    "        mention_annot_type = data['attributesFromSource'][attributeSource][source_type]['annotation-type']\n",
    "        mention_bib_link_source = data['attributesFromSource'][attributeSource][source_type]['bib-mention-linker-source']\n",
    "        mention_det_source = data['attributesFromSource'][attributeSource][source_type]['mention-detection-source']\n",
    "        \n",
    "    # bib entries\n",
    "    if source_type == bib_entries:\n",
    "        bib_entry_annot_type = data['attributesFromSource'][attributeSource][source_type]['annotation-type']\n",
    "        bib_entry_det_source = data['attributesFromSource'][attributeSource][source_type]['bib-detection-source']\n",
    "\n",
    "    # bib entry parses\n",
    "    if source_type == bib_entry_parses:\n",
    "        bib_parse_annot_type = data['attributesFromSource'][attributeSource][source_type]['annotation-type']\n",
    "        bib_parse_source = data['attributesFromSource'][attributeSource][source_type]['bib-parsing-source']\n",
    "        \n",
    "    # pdf plumber\n",
    "    if source_type == plumber:\n",
    "        plumber_annot_type = ['PlainText', 'PDF'] #always has annotations from both endpoints\n",
    "        plumber_source = data['attributesFromSource'][attributeSource][source_type]\n",
    "\n",
    "# all source type values and endpoints from data\n",
    "source_values = [[mention_annot_type, mention_bib_link_source, mention_det_source],\n",
    "                [bib_entry_annot_type, bib_entry_det_source],\n",
    "                [bib_parse_annot_type, bib_parse_source],\n",
    "                [plumber_annot_type, plumber_source]]\n",
    "\n",
    "# spot check of source types: outputs all the sources and what format they are stored in\n",
    "[source for source in source_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc696479",
   "metadata": {},
   "source": [
    "### 1b. Retrieve Annotations for tokens, rows, and pages\n",
    "Using the sources obtained from the previous cell, we will now retreive the annotations for each source depending on if they are in the annotation store as a PDF or plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e9ca3264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page to annotate: 14\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTE: For the provided sample, we are getting annotations from prod annotations-api.\n",
    "      When the data is actually run through SPP, they will be in dev annotations-api.\n",
    "      Will need to modify \"http://annotations-api.prod.s2....\" --> \"http://annotations-api.dev.s2....\"\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import boto3\n",
    "import requests\n",
    "import random # to get random page number to annotate\n",
    "\n",
    "from mmda.types.span import Span\n",
    "from mmda.types.annotation import SpanGroup, Box\n",
    "from mmda.types.document import Document\n",
    "\n",
    "\n",
    "# !!!! ANNOTATOR TODO: Record page # from output in annotation spreadsheet\n",
    "# get random page number to review and annotate\n",
    "page = random.randrange(1,15) #bailey todo: change range end at # of pages in pdf\n",
    "print(\"page to annotate:\", page)\n",
    "\n",
    "\n",
    "# method that gets url to help create span group\n",
    "def get_text(url: str) -> str:\n",
    "    s3 = boto3.resource('s3')\n",
    "    url_no_prefix = url[5:]\n",
    "    bucket, *key = url_no_prefix.split(\"/\")\n",
    "    key = \"/\".join(key)\n",
    "    with s3.Bucket(bucket).Object(key).get()['Body'] as f:\n",
    "        return f.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91394f",
   "metadata": {},
   "source": [
    "#### Part 1: PDF Plumber\n",
    "Get pdf plumber data - Need to use text id, text_url from this block in the rest of the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d1915e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_url: s3://ai2-s2-science-parse-plus-prod/document/17ada3c96ef888fc89f6b995d2edd19a45383423/pdfplumber-0.0.4/text\n",
      "\n",
      "text_id: 740c1d64752b4679a742544046cf5de3452cfef4\n",
      "SpanGroup(uuid='ef5d5569-2618-4e4b-8d31-e22451dc09fa', doc=<mmda.types.document.Document object at 0x7fea2f54f9d0>, metadata=Metadata({'id': None, 'type': 'Title', 'text': None}), spans=[Span(start=0, end=125, box=None)], box_group=None, id=None, type='Title', text='1\\nFunctions of FMS-like tyrosine kinase 3 (flt3) in zebrafish hematopoiesis and its\\nrelevance to human acute myeloid leukemia')\n"
     ]
    }
   ],
   "source": [
    "#PDF PLUMBER: 1\n",
    "#request annots where source = plumber_source\n",
    "resp1 = requests.get(f'http://annotations-api.prod.s2.allenai.org/pdf/{sha}/annotations?annotationSources=none&attributeSources={plumber_source}').json()\n",
    "\n",
    "#get text_url which is needed to get text (which is needed to make initial annotation doc per paper)\n",
    "text_url = resp1['attributesFromSource'][plumber_source]['text']\n",
    "print(\"text_url:\", text_url)\n",
    "\n",
    "#returns id and s3 url, use this to get text id\n",
    "resp2 = requests.post(\n",
    "    'http://annotations-api.prod.s2.allenai.org/plain-text/',\n",
    "    json={'s3Url': text_url}\n",
    ").json()\n",
    "text_id = resp2['id']\n",
    "print(\"\\ntext_id:\",text_id)\n",
    "\n",
    "#gets document id which is the same throughout all types of annotations; will resuse for future cells\n",
    "#be careful of plain-text vs. pdf endpoint\n",
    "resp3 = requests.get(f'http://annotations-api.prod.s2.allenai.org/plain-text/{text_id}/annotations'\n",
    "                     f'?annotationSources=vila-0.0.2|layout-parser-0.0.2|{plumber_source}'\n",
    "                     '&attributeSources=none').json()\n",
    "\n",
    "\n",
    "#getting annotations from plumber_source\n",
    "vila_annos = resp3['annotationsFromSource'][f'vila-0.0.2|layout-parser-0.0.2|{plumber_source}']['vila_span_groups']\n",
    "#print(resp3['annotationsFromSource'][f'vila-0.0.2|layout-parser-0.0.2|{plumber_source}']['vila_span_groups'])\n",
    "\n",
    "#need this to create span group\n",
    "text = get_text(text_url)\n",
    "vila_spangroups = []\n",
    "for anno in vila_annos:\n",
    "    vila_spangroups.append(\n",
    "        SpanGroup(\n",
    "            spans=[Span(start=anno['startChar'], end=anno['endChar'])],\n",
    "            type=anno['attributesFromSource'][f'vila-0.0.2|layout-parser-0.0.2|{plumber_source}']['type']\n",
    "        )\n",
    "    )\n",
    "\n",
    "#create initial document\n",
    "doc = Document(text)\n",
    "\n",
    "#annotate annotatiosn onto doc\n",
    "doc.annotate(vila=vila_spangroups)\n",
    "\n",
    "#spot check\n",
    "print(vila_spangroups[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c61fac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpanGroup(uuid='ef5d5569-2618-4e4b-8d31-e22451dc09fa', doc=<mmda.types.document.Document object at 0x7fea2f54f9d0>, metadata=Metadata({'id': None, 'type': 'Title', 'text': None}), spans=[Span(start=0, end=125, box=None)], box_group=None, id=None, type='Title', text='1\\nFunctions of FMS-like tyrosine kinase 3 (flt3) in zebrafish hematopoiesis and its\\nrelevance to human acute myeloid leukemia')\n"
     ]
    }
   ],
   "source": [
    "#PDF PLUMBER: 2\n",
    "def make_span_groups(text_spans, pdf_boxes):\n",
    "    \n",
    "    instance_tokens = []\n",
    "    for i, text_span in enumerate(text_spans):\n",
    "        box_info = pdf_boxes[i]\n",
    "        associated_box = Box(\n",
    "            l=box_info['x'], \n",
    "            t=box_info['y'], \n",
    "            w=box_info['width'], \n",
    "            h=box_info['height'], \n",
    "            page=box_info['page']\n",
    "        )\n",
    "\n",
    "        instance_tokens.append(\n",
    "            SpanGroup(\n",
    "                spans=[Span(start=text_span['startChar'], end=text_span['endChar'], box=associated_box)],\n",
    "                id=text_span['attributesFromSource']['pdfplumber-0.0.4']['id']\n",
    "\n",
    "            )\n",
    "        )\n",
    "    return instance_tokens\n",
    "    \n",
    "\n",
    "symbols = text\n",
    "pdf_plumber_text_annos_resp = requests.get(f'http://annotations-api.prod.s2.allenai.org/plain-text/{text_id}/annotations'\n",
    "                     '?annotationSources=pdfplumber-0.0.4'\n",
    "                     '&attributeSources=none').json()\n",
    "pdf_plumber_pdf_annos_resp = requests.get(f'http://annotations-api.prod.s2.allenai.org/pdf/{sha}/annotations'\n",
    "                     '?annotationSources=pdfplumber-0.0.4'\n",
    "                     '&attributeSources=none').json()\n",
    "\n",
    "#need these to later annotate boxgroups to the mmda doc\n",
    "token_spans = pdf_plumber_text_annos_resp['annotationsFromSource']['pdfplumber-0.0.4']['tokens']\n",
    "token_boxes = pdf_plumber_pdf_annos_resp['annotationsFromSource']['pdfplumber-0.0.4']['tokens']\n",
    "page_spans = pdf_plumber_text_annos_resp['annotationsFromSource']['pdfplumber-0.0.4']['pages']\n",
    "page_boxes = pdf_plumber_pdf_annos_resp['annotationsFromSource']['pdfplumber-0.0.4']['pages']\n",
    "row_spans = pdf_plumber_text_annos_resp['annotationsFromSource']['pdfplumber-0.0.4']['rows']\n",
    "row_boxes = pdf_plumber_pdf_annos_resp['annotationsFromSource']['pdfplumber-0.0.4']['rows']\n",
    "\n",
    "instance_tokens = make_span_groups(token_spans, token_boxes)\n",
    "instance_rows = make_span_groups(row_spans, row_boxes)\n",
    "instance_pages = make_span_groups(page_spans, page_boxes)\n",
    "\n",
    "# rows/pages specific to PDF Plumber annotations\n",
    "rows = pdf_plumber_text_annos_resp['annotationsFromSource']['pdfplumber-0.0.4']['rows']\n",
    "pages = pdf_plumber_text_annos_resp['annotationsFromSource']['pdfplumber-0.0.4']['pages']\n",
    "vila_span_groups = vila_spangroups\n",
    "print(vila_span_groups[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b2db3",
   "metadata": {},
   "source": [
    "#### Part 2: Mentions\n",
    "Get mentions annotations from annotation store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "23aa1bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpanGroup(uuid='e288110f-9a1f-47a6-b2d4-4f0ba087e6a3', doc=None, metadata=Metadata({'id': None, 'type': 0, 'text': None}), spans=[Span(start=4376, end=4381, box=None)], box_group=None, id=None, type=0, text='')\n"
     ]
    }
   ],
   "source": [
    "#retrieve mentions boxes and spans (box = pdf) (spans = plain-text)\n",
    "\n",
    "#annotation sources = variables found above\n",
    "#attribute sources = all\n",
    "ment_resp1 = requests.get(f'https://annotations-api.dev.s2.allenai.org/pdf/{sha}/'\n",
    "                     f'annotations?annotationSources={mention_det_source}&attributeSources=all').json()\n",
    "\n",
    "\n",
    "#Plain-Text endpoint - get spans\n",
    "ment_resp3 = requests.get(f'http://annotations-api.dev.s2.allenai.org/plain-text/{text_id}/annotations'\n",
    "                         f'?annotationSources={mention_det_source}'\n",
    "                         '&attributeSources=all').json()\n",
    "\n",
    "#getting annotations from mentions\n",
    "anno_mentions = ment_resp3['annotationsFromSource'][f'{mention_det_source}']['mentions']\n",
    "\n",
    "#need to combine spans and boxes into single span group, which can then be annotated onto mmda doc\n",
    "# method that combines box and text spans - specific to mentions\n",
    "def make_span_groups(text_spans, pdf_boxes):\n",
    "    \n",
    "    instance_tokens = []\n",
    "    for i, text_span in enumerate(text_spans):\n",
    "        box_info = pdf_boxes[i]\n",
    "        associated_box = Box(\n",
    "            l=box_info['x'], \n",
    "            t=box_info['y'], \n",
    "            w=box_info['width'], \n",
    "            h=box_info['height'], \n",
    "            page=box_info['page']\n",
    "        )\n",
    "\n",
    "        instance_tokens.append(\n",
    "            SpanGroup(\n",
    "                spans=[Span(start=text_span['startChar'], end=text_span['endChar'], box=associated_box)],\n",
    "                id=text_span['attributesFromSource'][f'{mention_det_source}']\n",
    "            )\n",
    "        )\n",
    "    return instance_tokens\n",
    "\n",
    "# create span group\n",
    "#initialize mentions spangroup list\n",
    "ment_spangroups = []\n",
    "for anno in anno_mentions: #sub in new variable here\n",
    "    ment_spangroups.append(\n",
    "        SpanGroup(\n",
    "            spans=[Span(start=anno['startChar'], end=anno['endChar'])],\n",
    "            type=anno['attributesFromSource'][f'{mention_det_source}']['group']\n",
    "        )\n",
    "    )\n",
    "\n",
    "symbols = text\n",
    "ment_text_annos_resp = requests.get(f'http://annotations-api.dev.s2.allenai.org/plain-text/{text_id}/annotations'\n",
    "                     f'?annotationSources={mention_det_source}'\n",
    "                     '&attributeSources=none').json()\n",
    "\n",
    "ment_pdf_annos_resp = requests.get(f'http://annotations-api.dev.s2.allenai.org/pdf/{sha}/annotations'\n",
    "                     f'?annotationSources={mention_det_source}'\n",
    "                     '&attributeSources=none').json()\n",
    "\n",
    "token_boxes = ment_pdf_annos_resp['annotationsFromSource'][f'{mention_det_source}']['mentions']\n",
    "token_spans = ment_text_annos_resp['annotationsFromSource'][f'{mention_det_source}']['mentions']\n",
    "\n",
    "instance_tokens = make_span_groups(token_spans, token_boxes)\n",
    "\n",
    "\n",
    "#annotate annotations onto doc\n",
    "doc.annotate(mentions=ment_spangroups)\n",
    "\n",
    "#print span group spot check\n",
    "print(ment_spangroups[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb99bd4",
   "metadata": {},
   "source": [
    "### Part 3: Bib-Entries\n",
    "Get bib-entry annotations from annotation store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "95d2c8b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'page_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [242]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m anno_bib \u001b[38;5;241m=\u001b[39m bib_resp1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotationsFromSource\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbib_entry_det_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib-entries\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#print(anno_bib)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# !!!! ANNOTATOR TODO: \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#doc.annotate(tokens=instance_tokens)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#doc.annotate(rows=instance_rows)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m instance \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbols\u001b[39m\u001b[38;5;124m\"\u001b[39m: symbols,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m : [sg\u001b[38;5;241m.\u001b[39mto_json() \u001b[38;5;28;01mfor\u001b[39;00m sg \u001b[38;5;129;01min\u001b[39;00m instance_tokens],\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m : [sg\u001b[38;5;241m.\u001b[39mto_json() \u001b[38;5;28;01mfor\u001b[39;00m sg \u001b[38;5;129;01min\u001b[39;00m instance_rows],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpages\u001b[39m\u001b[38;5;124m\"\u001b[39m : [sg\u001b[38;5;241m.\u001b[39mto_json() \u001b[38;5;28;01mfor\u001b[39;00m sg \u001b[38;5;129;01min\u001b[39;00m instance_pages],\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvila_span_groups\u001b[39m\u001b[38;5;124m\"\u001b[39m : [sg\u001b[38;5;241m.\u001b[39mto_json() \u001b[38;5;28;01mfor\u001b[39;00m sg \u001b[38;5;129;01min\u001b[39;00m vila_span_groups],\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_images\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[43mpage_images\u001b[49m\n\u001b[1;32m     32\u001b[0m }\n\u001b[1;32m     34\u001b[0m instance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvila_span_groups\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# need to create box groups\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# bib_entry_boxgroups_json to spangroups to json:\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'page_images' is not defined"
     ]
    }
   ],
   "source": [
    "#retrieve bib-entry annotations\n",
    "#pdf endpoint\n",
    "bib_resp1 = requests.get(f'https://annotations-api.dev.s2.allenai.org/pdf/{sha}/'\n",
    "                     f'annotations?annotationSources={bib_entry_det_source}&attributeSources=all').json()\n",
    "\n",
    "\n",
    "#plain-text endpoint\n",
    "#not actually being used here\n",
    "bib_resp3 = requests.get(f'http://annotations-api.dev.s2.allenai.org/plain-text/{text_id}/annotations'\n",
    "                         f'?annotationSources={bib_entry_det_source}'\n",
    "                         '&attributeSources=all').json()\n",
    "\n",
    "#getting annotations from mentions\n",
    "#you may need to change bib_resp1 to bib_resp3 if the annotation type listed is plain-text (rather than PDF)\n",
    "anno_bib = bib_resp1['annotationsFromSource'][f'{bib_entry_det_source}']['bib-entries']\n",
    "#print(anno_bib)\n",
    "\n",
    "#need pages, tokens, spans and rows\n",
    "# !!!! ANNOTATOR TODO: need to un-comment these annotation calls \n",
    "    #only do this once per run, otherwise it prompts you to overwrite \n",
    "#doc.annotate(pages=instance_pages)\n",
    "#doc.annotate(tokens=instance_tokens)\n",
    "#doc.annotate(rows=instance_rows)\n",
    "\n",
    "# need to create box groups\n",
    "# bib_entry_boxgroups_json to spangroups to json:\n",
    "from mmda.types.annotation import BoxGroup\n",
    "from copy import copy\n",
    "import itertools\n",
    "\n",
    "def box_groups_json_to_boxgroups(box_groups_json):\n",
    "\n",
    "    counter = itertools.count()\n",
    "    \n",
    "    # make BoxGroups from Json\n",
    "    boxgroups = []\n",
    "    for bg in box_groups_json:\n",
    "        box_info = bg\n",
    "        box = Box(\n",
    "            l=box_info['x'], \n",
    "            t=box_info['y'], \n",
    "            w=box_info['width'], \n",
    "            h=box_info['height'],            \n",
    "            page=box_info['page']\n",
    "        )\n",
    "        boxgroups.append(\n",
    "        BoxGroup(boxes=[box],\n",
    "                 id=next(counter) # OR update models?\n",
    "                )\n",
    "        )\n",
    "    print(boxgroups[0])\n",
    "    #doc.annotate(bibs=boxgroups)\n",
    "    return boxgroups\n",
    "\n",
    "bib_box_groups = box_groups_json_to_boxgroups(anno_bib)\n",
    "\n",
    "# !!!! ANNOTATOR TODO: uncomment \"doc.annotate...\" for each run\n",
    "#annotate annotations onto doc (only do once or get overwrite error)\n",
    "#doc.annotate(bibs=bib_box_groups)\n",
    "\n",
    "#check that they are spans\n",
    "print(doc.bibs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad96b13",
   "metadata": {},
   "source": [
    "### Part 4: Bib-Parse \n",
    "Get bib-parse-entry annotations from annotation store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e00c514d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpanGroup(uuid='df58a24b-12bc-49ce-9c0a-d5976463a10c', doc=<mmda.types.document.Document object at 0x7fea2f54f9d0>, metadata=Metadata({'id': None, 'type': {'text': 'The role of FLT3 in haematopoietic malignancies', 'group': 0}, 'text': None}), spans=[Span(start=34134, end=34181, box=None)], box_group=None, id=None, type={'text': 'The role of FLT3 in haematopoietic malignancies', 'group': 0}, text='The role of FLT3 in haematopoietic malignancies')\n"
     ]
    }
   ],
   "source": [
    "#retrieve bib parse data\n",
    "#pdf endpoint\n",
    "bib_parse_resp1 = requests.get(f'https://annotations-api.dev.s2.allenai.org/pdf/{sha}/'\n",
    "                     f'annotations?annotationSources={bib_parse_source}&attributeSources={bib_parse_source}').json()\n",
    "\n",
    "#plain-text endpoint\n",
    "#not actually being used here\n",
    "bib_parse_resp3 = requests.get(f'http://annotations-api.dev.s2.allenai.org/plain-text/{text_id}/annotations'\n",
    "                         f'?annotationSources={bib_parse_source}'\n",
    "                         '&attributeSources=all').json()\n",
    "#print(bib_parse_resp3)\n",
    "\n",
    "#getting annotations from bib parse\n",
    "#you may need to change bib_resp1 to bib_resp3 if the annotation type listed is plain-text (rather than PDF)\n",
    "anno_bib_parse = bib_parse_resp3['annotationsFromSource'][f'{bib_parse_source}']['bib_entry_title']\n",
    "#print(anno_bib_parse)\n",
    "\n",
    "#initialize bib parse spangroup list\n",
    "bib_parse_spangroups = []\n",
    "\n",
    "# need this to create span group\n",
    "for anno in anno_bib_parse: #sub in new variable here\n",
    "    bib_parse_spangroups.append(\n",
    "        SpanGroup(\n",
    "            spans=[Span(start=anno['startChar'], end=anno['endChar'])],\n",
    "            type=anno['attributesFromSource'][f'{bib_parse_source}']\n",
    "        )\n",
    "    )\n",
    "\n",
    "#annotate annotations onto doc\n",
    "doc.annotate(bib_parse=bib_parse_spangroups)\n",
    "\n",
    "#print span group spot check\n",
    "print(bib_parse_spangroups[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038e9f8",
   "metadata": {},
   "source": [
    "### 1c. Check to make sure you have annotated all fields onto mmda doc\n",
    "Should be: vila(pdfplumber), mentions, bib_entries, bib_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "883af2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vila', 'mentions', 'bib_parse', 'tokens', 'pages', 'bibs']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpanGroup(uuid='97a0e9b5-b1a4-47d3-a7f9-91dc4da92686', doc=<mmda.types.document.Document object at 0x7fea2f54f9d0>, metadata=Metadata({'id': {'group': 0}, 'type': None, 'text': None}), spans=[Span(start=4376, end=4381, box=Box(l=0.3673529411764706, t=0.45673090681818185, w=0.027257940653594773, h=0.00939974747474745, page=2))], box_group=None, id={'group': 0}, type=None, text='12,13')"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(doc.fields)\n",
    "doc.mentions[0].tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ccd6f",
   "metadata": {},
   "source": [
    "## 2. Visalize Paper and Draw boxes on mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d9da1c",
   "metadata": {},
   "source": [
    "Use draw boxes to visualize each mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "699b78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def make_boxgroups_mentions(doc):\n",
    "\n",
    "    result_boxes_list = defaultdict(list)\n",
    "    \n",
    "    dictionary_of_boxes = defaultdict(list)\n",
    "    \n",
    "    for mention in doc.mentions:\n",
    "        for token in mention.tokens:\n",
    "            dictionary_of_boxes[token.box.page].append(token.box)\n",
    "    \n",
    "    \n",
    "    for page, list_of_boxes in dictionary_of_boxes.items():\n",
    "        page_w, page_h = doc.images[page].size\n",
    "\n",
    "\n",
    "        for box in list_of_boxes:\n",
    "            if box.page == p:\n",
    "                result_boxes_list[page].append(lpe.Rectangle(\n",
    "                        box.l * page_w,\n",
    "                        box.t * page_h,\n",
    "                        (box.l + box.w) * page_w,\n",
    "                        (box.t + box.h) * page_h\n",
    "                    ))\n",
    "            else:\n",
    "                raise ValueError('Page number')\n",
    "    return result_boxes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c53be4f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SpanGroup' object has no attribute 'box'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [261]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mmake_boxgroups_mentions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [260]\u001b[0m, in \u001b[0;36mmake_boxgroups_mentions\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mention \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mmentions:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m mention\u001b[38;5;241m.\u001b[39mtokens:\n\u001b[0;32m---> 10\u001b[0m         dictionary_of_boxes[\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbox\u001b[49m\u001b[38;5;241m.\u001b[39mpage]\u001b[38;5;241m.\u001b[39mappend(token\u001b[38;5;241m.\u001b[39mbox)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page, list_of_boxes \u001b[38;5;129;01min\u001b[39;00m dictionary_of_boxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     14\u001b[0m     page_w, page_h \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mimages[page]\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[0;32m~/Projects/SP_end_to_end/mmda/mmda/types/annotation.py:89\u001b[0m, in \u001b[0;36mAnnotation.__getattr__\u001b[0;34m(self, field)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc\u001b[38;5;241m.\u001b[39mfields:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc\u001b[38;5;241m.\u001b[39mfind_overlapping(\u001b[38;5;28mself\u001b[39m, field)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SpanGroup' object has no attribute 'box'"
     ]
    }
   ],
   "source": [
    "test = make_boxgroups_mentions(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8ed9e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw boxes function\n",
    "import layoutparser.elements as lpe\n",
    "import layoutparser.visualization as lpv\n",
    "\n",
    "def draw_boxes(groups, canvas, color, **kwargs):\n",
    "    viz = []\n",
    "\n",
    "    for group in groups:\n",
    "        for box in group:\n",
    "            viz.append(lpe.TextBlock(box, type=f\"color\"))\n",
    "\n",
    "    return lpv.draw_box(\n",
    "        canvas, \n",
    "        viz,\n",
    "        color_map={'color': color},\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d7772802",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'make_boxes' from 'extract_citation_mentions' (/Users/baileyk/Projects/SP_end_to_end/extract-stuff-from-pdfs/extract_citation_mentions/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [164]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# adding folder2 to system path; can't import for some reason\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/baileyk/Projects/SP_end_to_end/extract-stuff-from-pdfs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mextract_citation_mentions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_pdf, make_boxes\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrasterizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrasterizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDF2ImageRasterizer\n\u001b[1;32m     10\u001b[0m paper_sha \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m17ada3c96ef888fc89f6b995d2edd19a45383423\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'make_boxes' from 'extract_citation_mentions' (/Users/baileyk/Projects/SP_end_to_end/extract-stuff-from-pdfs/extract_citation_mentions/__init__.py)"
     ]
    }
   ],
   "source": [
    "# importing sys\n",
    "import sys\n",
    " \n",
    "# adding folder2 to system path; can't import for some reason\n",
    "sys.path.insert(0, '/Users/baileyk/Projects/SP_end_to_end/extract-stuff-from-pdfs')\n",
    "\n",
    "from extract_citation_mentions import download_pdf, make_boxes\n",
    "from mmda.rasterizers.rasterizer import PDF2ImageRasterizer\n",
    "\n",
    "paper_sha = '17ada3c96ef888fc89f6b995d2edd19a45383423'\n",
    "page = 0\n",
    "\n",
    "matches = papers[sha].pages[page]\n",
    "print(f\"found={matches.found} missed={matches.missed} incorrect/extra={matches.incorrect}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881341a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = download_pdf(paper_sha)\n",
    "images = PDF2ImageRasterizer().rasterize(pdf_path, dpi=144)\n",
    "\n",
    "gold = [m.gold for m in matches.matches if m.gold]\n",
    "baseline = [m.baseline for m in matches.matches if m.baseline]\n",
    "\n",
    "image = images[page]\n",
    "image = draw_boxes(make_boxes(gold, image), image, 'yellow')\n",
    "image = draw_boxes(make_boxes(baseline, image), image, 'blue', box_width=3)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a81f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
